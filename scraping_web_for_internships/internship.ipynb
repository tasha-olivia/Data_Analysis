{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://internshala.com/internships/'\n",
    "results = requests.get(website)\n",
    "\n",
    "content = results.text\n",
    "soup= BeautifulSoup(content, 'lxml')\n",
    "internship_box  = soup.find('div', {'id': 'internship_list_container'})\n",
    "# print(internship_box.prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internshipSpecifications(ind_int_match):\n",
    "    internship_position_list = []\n",
    "    company_name_list = []\n",
    "    location_list = []\n",
    "    date_posted_list =  []\n",
    "    duration_list = []\n",
    "\n",
    "    # loop through all individual internships in the page and obtain all nessecery information\n",
    "    for i in range(0, len(ind_int_match)):\n",
    "        ind_int_div = soup.find('div', {'id': ind_int_match[i]})\n",
    "        internship_position = ind_int_div.find('h3').get_text(strip=True)\n",
    "        company_name = ind_int_div.find('h4').get_text(strip=True)\n",
    "        location = ind_int_div.find('div', {'id': 'location_names'}).get_text(strip=True)\n",
    "        date_posted =ind_int_div.find(class_ = 'status-container').get_text(strip=True)\n",
    "\n",
    "        internship_position_list.append(internship_position)\n",
    "        company_name_list.append(company_name)\n",
    "        date_posted_list.append(date_posted)\n",
    "        location_list.append(location)\n",
    "\n",
    "    return internship_position_list, company_name_list, date_posted_list, location_list\n",
    "\n",
    "    # print('Date posted: ', len(date_posted_list))\n",
    "    # print('internship position', len(internship_position_list))\n",
    "    # print('Company name', len(company_name_list))\n",
    "    # print('Location', len(location_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://internshala.com/internships/page-1\n",
      "https://internshala.com/internships/page-2\n",
      "https://internshala.com/internships/page-3\n"
     ]
    }
   ],
   "source": [
    "# obtian number of pages you have to loop through\n",
    "page_len = soup.find('span', {'id': 'total_pages'}).get_text(strip=True)\n",
    "df = pd.DataFrame()\n",
    "\n",
    "ipl_list = []\n",
    "cn_list = []\n",
    "dpl_list = []\n",
    "locl_list = []\n",
    "\n",
    "for j in range(1, int(page_len)):\n",
    "# for j in range(1, 4):\n",
    "    website = 'https://internshala.com/internships/page-' + str(j)\n",
    "    results = requests.get(website)\n",
    "    content = results.text\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    internship_box = soup.find('div', {'id': 'internship_list_container'})\n",
    "\n",
    "    # gets the id of the box containing all internships\n",
    "    pattern = r'internship_list_container_\\d'\n",
    "    internship_box_str = str(internship_box)\n",
    "    match = re.findall(pattern, internship_box_str)\n",
    "    # print(match)\n",
    "\n",
    "    # gets the id of all internships in the internship box identified above\n",
    "    pattern2 = r'individual_internship_\\d+'\n",
    "    individual_intern_matches = re.findall(pattern2, internship_box_str)\n",
    "    # print(len(ind_intern_matches))\n",
    "    \n",
    "    intern_pos_list, comp_name_list, date_post_list, loc_list = internshipSpecifications(individual_intern_matches)\n",
    "\n",
    "    ipl_list.extend(intern_pos_list)\n",
    "    cn_list.extend(comp_name_list)\n",
    "    dpl_list.extend(date_post_list)\n",
    "    locl_list.extend(loc_list)\n",
    "\n",
    "    # print(website)\n",
    "# print(ipl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              internship_postion  \\\n",
      "0           Business Development   \n",
      "1  E-Commerce Catalog Management   \n",
      "2                      Marketing   \n",
      "3           Human Resources (HR)   \n",
      "4                    Fundraising   \n",
      "\n",
      "                                     company_name    date_posted  \\\n",
      "0               Heterize Infotech Private Limited  Few hours ago   \n",
      "1               Heterize Infotech Private Limited  Few hours ago   \n",
      "2                               TheHealthMechanix     5 days ago   \n",
      "3               Heterize Infotech Private Limited     5 days ago   \n",
      "4  Odisha Development Management Programme (ODMP)     4 days ago   \n",
      "\n",
      "         location  \n",
      "0          Indore  \n",
      "1          Indore  \n",
      "2           Delhi  \n",
      "3          Indore  \n",
      "4  Work From Home  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'internship_postion': ipl_list, 'company_name': cn_list, 'date_posted': dpl_list, 'location': locl_list})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['internship_list_container_1']\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "# gets the id of the box containing all internships\n",
    "pattern = r'internship_list_container_\\d'\n",
    "internship_box_str = str(internship_box)\n",
    "match = re.findall(pattern, internship_box_str)\n",
    "print(match)\n",
    "\n",
    "# gets the id of all internships in the internship box identified above\n",
    "pattern2 = r'individual_internship_\\d+'\n",
    "ind_intern_matches = re.findall(pattern2, internship_box_str)\n",
    "print(len(ind_intern_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Video Production \n",
      "Unbroken Kraft Music\n",
      "Ghaziabad\n",
      "StartsÂ immediatelyImmediately\n",
      "1 week ago\n"
     ]
    }
   ],
   "source": [
    "ind_int_div = soup.find('div', {'id': ind_intern_matches[0]})\n",
    "internship_postion = ind_int_div.find('h3').get_text()\n",
    "print(internship_postion)\n",
    "company_name = ind_int_div.find('h4').get_text(strip=True)\n",
    "print(company_name)\n",
    "location = ind_int_div.find('div', {'id': 'location_names'}).get_text(strip=True)\n",
    "print(location)\n",
    "duration = ind_int_div.find(class_ = 'item_body').getText(strip= True)\n",
    "print(duration)\n",
    "date_posted = ind_int_div.find(class_ ='status-container').get_text(strip= True)\n",
    "print(date_posted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48] \n",
      "unexpected []\n"
     ]
    }
   ],
   "source": [
    "# print(company_name_list)\n",
    "index_list_correct = []\n",
    "index_list_incorrect = []\n",
    "for i in range(0, len(ind_intern_matches)):\n",
    "    ind_int_div = soup.find('div', {'id': ind_intern_matches[i]})\n",
    "    int_position = ind_int_div.find('h3').get_text(strip=True)\n",
    "    com_name = ind_int_div.find('h4').get_text(strip=True)\n",
    "    location = ind_int_div.find('div', {'id': 'location_names'}).get_text(strip=True)\n",
    "    date_posted =ind_int_div.find(class_ = 'status-container').get_text(strip=True)\n",
    "\n",
    "    if (location != '' and com_name != ''and int_position !='' and date_posted != ''):\n",
    "        index_list_correct.append(i)\n",
    "    else:\n",
    "        index_list_incorrect.append(i)\n",
    "print('expected', index_list_correct, '\\nunexpected', index_list_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "page_len = soup.find('span', {'id': 'total_pages'}).get_text(strip=True)\n",
    "print(type(page_len))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
